import streamlit as st
import pandas as pd
import joblib

# ===== é é¢è¨­å®š =====
st.set_page_config(page_title="ä¿¡ç”¨å¡å³æ™‚é¢¨æ§ç³»çµ± Demo", page_icon="ğŸ’³", layout="wide")

# ===== é¡¯ç¤ºæ¨™é¡Œèˆ‡ç³»çµ±æµç¨‹åœ– =====
st.title("ğŸ’³ ä¿¡ç”¨å¡å³æ™‚é¢¨æ§ç³»çµ± Demo")
st.caption("æœ¬ç³»çµ±æ¨¡æ“¬çœŸå¯¦éŠ€è¡Œç’°å¢ƒä¸­å³æ™‚ä¿¡ç”¨å¡äº¤æ˜“é¢¨éšªåµæ¸¬æµç¨‹ï¼Œæ•¸æ“šç¶“åŒ¿ååŒ–è™•ç†ï¼ˆKaggle/ULBï¼‰ï¼Œåƒ…ä½œæ•™è‚²ç”¨é€”ã€‚")

with st.expander("ğŸ“ˆ ç³»çµ±æµç¨‹åœ–èªªæ˜"):
    st.markdown("""
    1. **åˆ·å¡äº¤æ˜“æµå…¥**ï¼ˆæ¨¡æ“¬ç”±APIæˆ–æ‰¹æ¬¡æª”åŒ¯å…¥ï¼‰
    2. **æ¨¡å‹è¨ˆç®—é¢¨éšªåˆ†æ•¸**ï¼ˆè¼¸å‡º0~1ä¹‹é–“çš„è©æ¬ºæ©Ÿç‡ï¼‰
    3. **é–€æª»åˆ¤æ–·**ï¼ˆThresholdï¼šé¢¨æ§ç­–ç•¥çš„é—œéµèª¿ç¯€ï¼‰
    4. **æ¨™è¨˜é«˜é¢¨éšªäº¤æ˜“**ï¼ˆé€²å…¥äººå·¥å¯©æ ¸æˆ–è‡ªå‹•æš«åœï¼‰
    """)

# ===== è¼‰å…¥æ¨¡å‹ =====
@st.cache_resource
def load_model():
    return joblib.load("fraud_lr.pkl")

model = load_model()

# ===== æ¨¡å‹éœ€è¦çš„ç‰¹å¾µæ¬„ä½æ¸…å–® =====
EXPECTED_FEATURES = [
    'Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',
    'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',
    'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'
]

# ===== æ¬„ä½è§£èªªè¡¨ =====
feature_desc = {
    'Time': 'è·é›¢ç¬¬ä¸€ç­†äº¤æ˜“çš„ç§’æ•¸ï¼ˆè§€å¯Ÿäº¤æ˜“æ™‚é–“åˆ†ä½ˆï¼‰',
    'Amount': 'äº¤æ˜“é‡‘é¡ (â‚¬)',
}
for i in range(1, 29):
    feature_desc[f'V{i}'] = f'åŒ¿ååŒ–ç‰¹å¾µ {i}ï¼ˆç”±åŸå§‹äº¤æ˜“ç¶“PCAé™ç¶­ï¼‰'

# ===== æª”æ¡ˆä¸Šå‚³ =====
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³äº¤æ˜“ CSV æª”æ¡ˆ", type=["csv"])

if uploaded_file is not None:
    df_raw = pd.read_csv(uploaded_file)

    # ===== æ¬„ä½æª¢æŸ¥ =====
    missing_cols = [col for col in EXPECTED_FEATURES if col not in df_raw.columns]
    if missing_cols:
        st.error(f"âŒ æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_cols}")
        st.stop()

    # ä¸Ÿæ‰å¤šé¤˜æ¬„ä½ï¼Œä¸¦æ’åº
    df = df_raw[EXPECTED_FEATURES]

    # ===== é¡¯ç¤ºæ¬„ä½èªªæ˜è¡¨ =====
    st.subheader("ğŸ“ æ¬„ä½ä¸­æ–‡è§£èªª")
    desc_df = pd.DataFrame.from_dict(feature_desc, orient='index', columns=["èªªæ˜"])
    st.table(desc_df)

    # ===== é–€æª»æ»‘æ¡¿ =====
    thr = st.slider(
        "âš ï¸ é¢¨éšªé–€æª» (Threshold)",
        0.01, 0.99, 0.5, 0.01,
        help="èª¿ä½å¯æŠ“åˆ°æ›´å¤šå¯ç–‘äº¤æ˜“(Recallâ†‘)ï¼Œä½†èª¤å ±å¤šï¼›èª¿é«˜èª¤å ±å°‘ä½†å¯èƒ½æ¼æ‰è©æ¬º"
    )

    # ===== é æ¸¬ =====
    prob = model.predict_proba(df)[:, 1]
    pred = (prob >= thr).astype(int)

    out = df.copy()
    out["fraud_prob"] = prob
    out["prediction"] = pred

    # ===== çµ±è¨ˆå¡ç‰‡ =====
    total_txn = len(out)
    total_fraud = int((pred == 1).sum())
    fraud_ratio = (total_fraud / total_txn) * 100

    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“Š ç¸½äº¤æ˜“æ•¸", total_txn)
    col2.metric("ğŸš¨ ç–‘ä¼¼è©æ¬ºç­†æ•¸", total_fraud)
    col3.metric("ğŸ“ˆ ç–‘ä¼¼è©æ¬ºæ¯”ä¾‹ (%)", f"{fraud_ratio:.2f}")

    # ===== é«˜é¢¨éšªäº¤æ˜“è¡¨æ ¼ =====
    st.subheader("ğŸ” é«˜é¢¨éšªäº¤æ˜“ï¼ˆå‰ 20 ç­†ï¼‰")
    st.dataframe(out.sort_values(by="fraud_prob", ascending=False).head(20))

    # ===== ä¸‹è¼‰å®Œæ•´çµæœ =====
    st.download_button(
        label="ğŸ’¾ ä¸‹è¼‰å®Œæ•´åˆ†æçµæœ CSV",
        data=out.to_csv(index=False),
        file_name="predictions.csv",
        mime="text/csv"
    )

    # ===== æ¯”è³½è¬›è§£æç¤º =====
    with st.expander("ğŸ“¢ è¬›è§£æç¤º"):
        st.markdown("""
        - **æ¬„ä½è§£èªª**ï¼šå…ˆä»‹ç´¹Timeã€Amountï¼Œå†èªªV1~V28æ˜¯åŒ¿ååŒ–ç‰¹å¾µã€‚
        - **é–€æª»èª¿æ•´**ï¼šå±•ç¤ºä¸åŒThresholdä¸‹æŠ“åˆ°çš„å¯ç–‘äº¤æ˜“æ•¸è®ŠåŒ–ï¼Œè§£é‡‹Precision/Recallçš„å–æ¨ã€‚
        - **çµæœè§£æ**ï¼šæŒ‡è‘—é«˜æ©Ÿç‡çš„äº¤æ˜“ï¼Œèªªæ˜ç³»çµ±æœƒå„ªå…ˆè®“äººå·¥å¯©æ ¸ã€‚
        - **å ´æ™¯æ‡‰ç”¨**ï¼šçœŸå¯¦éŠ€è¡Œå¯æ¯æ—¥æ‰¹æ¬¡åŒ¯å…¥äº¤æ˜“ï¼Œæˆ–å³æ™‚æ¥APIæµï¼Œæ¯ç­†äº¤æ˜“ç«‹åˆ»è¨ˆç®—é¢¨éšªåˆ†æ•¸ã€‚
        """)

else:
    st.info("â¬†ï¸ è«‹ä¸Šå‚³äº¤æ˜“è³‡æ–™ CSV é–‹å§‹åˆ†æï¼ˆå¿…é ˆåŒ…å« Time, V1-V28, Amount æ¬„ä½ï¼‰")