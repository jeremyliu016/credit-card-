import streamlit as st
import pandas as pd
import joblib
import numpy as np
import time

# ===== é é¢è¨­å®š =====
st.set_page_config(page_title="ä¿¡ç”¨å¡å³æ™‚é¢¨æ§ç³»çµ± Demo", page_icon="ğŸ’³", layout="wide")
st.title("ğŸ’³ ä¿¡ç”¨å¡å³æ™‚é¢¨æ§ç³»çµ± Demo")
st.caption("æ¨¡æ“¬éŠ€è¡Œå³æ™‚ä¿¡ç”¨å¡äº¤æ˜“é¢¨éšªåµæ¸¬æµç¨‹ï¼Œæ•¸æ“šä¾†è‡ª Kaggle/ULBï¼Œç¶“åŒ¿ååŒ–è™•ç†ï¼Œåƒ…ä¾›æ•™è‚²ç”¨é€”ã€‚")

# ===== æµç¨‹èªªæ˜ =====
with st.expander("ğŸ“ˆ ç³»çµ±æµç¨‹åœ–èªªæ˜"):
    st.markdown("""
    1. **åˆ·å¡äº¤æ˜“æµå…¥**ï¼ˆæ¨¡æ“¬ç”¨CSVä¸Šå‚³ï¼‰
    2. **æ¨¡å‹è¨ˆç®—é¢¨éšªåˆ†æ•¸**ï¼ˆè¼¸å‡ºè©æ¬ºæ©Ÿç‡ 0~1ï¼‰
    3. **é–€æª»åˆ¤æ–·**ï¼ˆThresholdï¼šé¢¨æ§ç­–ç•¥å³æ™‚èª¿æ•´ï¼‰
    4. **æ¨™è¨˜é«˜é¢¨éšªäº¤æ˜“**ï¼ˆäººå·¥å¯©æ ¸æˆ–æš«åœäº¤æ˜“ï¼‰
    """)

# ===== è¼‰å…¥æ¨¡å‹ =====
@st.cache_resource
def load_model():
    return joblib.load("fraud_lr.pkl")
model = load_model()

# ===== æ¨¡å‹ç‰¹å¾µæ¬„ä½ =====
EXPECTED_FEATURES = [
    'Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',
    'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',
    'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'
]

# ===== æ¬„ä½è§£é‡‹è¡¨ =====
feature_desc = {'Time': 'è·ç¬¬ä¸€ç­†äº¤æ˜“çš„ç§’æ•¸ï¼ˆäº¤æ˜“æ™‚é–“å·®ï¼‰', 'Amount': 'äº¤æ˜“é‡‘é¡ (â‚¬)'}
for i in range(1, 29):
    feature_desc[f'V{i}'] = f'åŒ¿ååŒ–ç‰¹å¾µ {i}ï¼ˆç”±åŸå§‹äº¤æ˜“ç¶“ PCA é™ç¶­ï¼‰'

# ===== ä¸Šå‚³æª”æ¡ˆ =====
uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³äº¤æ˜“ CSV æª”æ¡ˆ", type=["csv"])

if uploaded_file:
    df_raw = pd.read_csv(uploaded_file)

    # æ¬„ä½æª¢æŸ¥
    missing_cols = [col for col in EXPECTED_FEATURES if col not in df_raw.columns]
    if missing_cols:
        st.error(f"âŒ æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
        st.stop()
    df = df_raw[EXPECTED_FEATURES]

    # ===== é¡¯ç¤ºæ¬„ä½è§£é‡‹ =====
    st.subheader("ğŸ“ æ¬„ä½ä¸­æ–‡è§£é‡‹")
    st.table(pd.DataFrame.from_dict(feature_desc, orient='index', columns=["èªªæ˜"]))

    # ===== é–€æª»æ»‘æ¡¿ =====
    thr = st.slider("âš ï¸ é¢¨éšªé–€æª» (Threshold)", 0.01, 0.99, 0.5, 0.01,
                    help="ä½é–€æª» â†’ Recallé«˜ä½†èª¤å ±å¤šï¼›é«˜é–€æª» â†’ èª¤å ±å°‘ä½†æ¼å ±å¤š")

    # ===== åŠ å…¥ç­‰å¾…æç¤º =====
    with st.spinner("â³ è«‹ç¨ç­‰ï¼Œæ­£åœ¨åˆ†æäº¤æ˜“è³‡æ–™..."):
        time.sleep(1.5)  # æ¨¡æ“¬å»¶é²

        # é æ¸¬
        prob = model.predict_proba(df)[:, 1]
        pred = (prob >= thr).astype(int)
        out = df.copy()
        out["fraud_prob"] = prob
        out["prediction"] = pred

    # ===== çµ±è¨ˆå¡ç‰‡ =====
    total_txn = len(out)
    total_fraud = int((pred == 1).sum())
    fraud_ratio = total_fraud / total_txn * 100
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“Š ç¸½äº¤æ˜“æ•¸", total_txn)
    col2.metric("ğŸš¨ ç–‘ä¼¼è©æ¬ºç­†æ•¸", total_fraud)
    col3.metric("ğŸ“ˆ ç–‘ä¼¼è©æ¬ºæ¯”ä¾‹(%)", f"{fraud_ratio:.2f}")

    # ===== é«˜é¢¨éšªäº¤æ˜“è¡¨ =====
    st.subheader("ğŸ” é«˜é¢¨éšªäº¤æ˜“ï¼ˆå‰ 20 ç­†ï¼‰")
    top20 = out.sort_values(by="fraud_prob", ascending=False).head(20)
    st.dataframe(top20)

    # ===== å–®ç­†äº¤æ˜“é¢¨éšªåŸå› åˆ†æ =====
    st.subheader("ğŸ“¢ é¢¨éšªåŸå› è§£é‡‹")
    coeffs = model.named_steps['clf'].coef_[0]  # Logistic Regression ä¿‚æ•¸
    selected_index = st.selectbox("é¸æ“‡äº¤æ˜“ç´¢å¼•ç·¨è™Ÿ", top20.index.tolist())

    if selected_index:
        txn = out.loc[selected_index, EXPECTED_FEATURES]
        contrib = coeffs * txn.values  # ç‰¹å¾µè²¢ç»åˆ†æ•¸
        contrib_df = pd.DataFrame({
            "ç‰¹å¾µ": EXPECTED_FEATURES,
            "æ•¸å€¼": txn.values,
            "å½±éŸ¿åˆ†æ•¸": contrib,
            "å½±éŸ¿æ–¹å‘": ["å¢åŠ é¢¨éšª" if c > 0 else "é™ä½é¢¨éšª" for c in contrib]
        }).sort_values(by="å½±éŸ¿åˆ†æ•¸", key=lambda x: abs(x), ascending=False)

        st.write(f"ğŸ’¡ äº¤æ˜“ç´¢å¼• {selected_index} çš„é¢¨éšªåˆ†æ•¸: {out.loc[selected_index,'fraud_prob']:.4f}")
        st.table(contrib_df.head(10))

else:
    st.info("â¬†ï¸ è«‹ä¸Šå‚³äº¤æ˜“è³‡æ–™ CSV é–‹å§‹åˆ†æï¼ˆå¿…é ˆåŒ…å« Time, V1-V28, Amount æ¬„ä½ï¼‰")